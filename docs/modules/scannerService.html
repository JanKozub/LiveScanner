<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>modules.scannerService API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>modules.scannerService</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from PIL import Image
import cv2
import numpy as np


class ScannerService:
    &#34;&#34;&#34;
    A class used to perform various scanning operations.

    Attributes
    ----------
    video : cv2.VideoCapture or None
        Video capture object for webcam (default None)
    frameWidth : int
        Width of the video frame (default 1920)
    frameHeight : int
        Height of the video frame (default 1080)
    edgeSize : int
        Size of the edge to crop (default 0)
    oldCoordinates : list
        List to store old coordinates (default empty list)
    colorValues : list of array
        HSV color range for pen detection
    kernel : np.ndarray
        Kernel for morphological operations (default np.ones((5, 5)))
    noiseArea : int
        Minimum area to be considered as valid pen detection (default 200)
    canvas : np.ndarray
        Canvas to draw the detected pen movements (default None)
    penCords : tuple
        Coordinates of the pen (default (0, 0))
    penColor : tuple
        Color of the pen (default [255, 0, 0])

    Methods
    -------
    preProcessing(image: Image):
        Preprocesses the image to find edges.
    getCornerPoints(image: Image):
        Finds the corner points of the largest contour.
    getWarp(image: Image, pageCoordinates: np.ndarray):
        Warps the image based on the given coordinates.
    setPerspective(image: Image, cords: np.ndarray):
        Sets the perspective transform for the image.
    postProcess(image: Image):
        Post-processes the image by rotating and cropping edges.
    processImage(image: Image):
        Processes the image to find and warp the largest contour.
    getPenFromImage(image: Image):
        Detects the pen in the image and draws its movement on the canvas.
    startScanner():
        Starts the video capture for scanning.
    stopScanner():
        Stops the video capture.
    getFinalImage():
        Gets the final processed image with pen movements.
    getColorsImage(lower: np.ndarray, higher: np.ndarray):
        Gets the image filtered by the specified HSV color range.
    mergeImages(bottomLayer: Image, topLayer: Image):
        Merges two images with alpha blending.
    &#34;&#34;&#34;

    def __init__(self, colorValues: [np.array, np.array]):
        &#34;&#34;&#34;
        :param colorValues:
            Color values of detected pen(default read from file)
        &#34;&#34;&#34;

        self.video: cv2.VideoCapture | None = None
        self.frameWidth: int = 1920
        self.frameHeight: int = 1080
        self.edgeSize: int = 0
        self.oldCoordinates: list = []
        self.colorValues: [np.array, np.array] = colorValues
        self.kernel: np.ndarray = np.ones((5, 5))
        self.noiseArea: int = 200
        self.canvas: np.array = None
        self.penCords: tuple[int, int] = (0, 0)
        self.penColor: tuple[int, int, int] = (255, 0, 0)

    def preProcessing(self, image: Image):
        &#34;&#34;&#34;
        Preprocesses the image to find edges.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The preprocessed image with edges detected.
        &#34;&#34;&#34;

        imgGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Gray image
        imgBlur = cv2.GaussianBlur(imgGray, (1, 1), 1)  # Blur Image - easing edges
        imgCanny = cv2.Canny(imgBlur, 100, 300)  # Canny Image - canny algo to find edges

        # extending the found edges and then eroding it to smoothen the image
        imgDilate = cv2.dilate(imgCanny, self.kernel, iterations=2)
        imgErode = cv2.erode(imgDilate, self.kernel, iterations=1)
        return imgErode

    @staticmethod
    def getCornerPoints(image: Image):
        &#34;&#34;&#34;
        Finds the corner points of the largest contour.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The corner points of the largest contour.
        &#34;&#34;&#34;

        cornerPointsOfMaxArea = np.array([])
        maxArea = 0
        contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area &gt; 100000:  # area in px x px
                peri = cv2.arcLength(cnt, True)  # perimeter of the closed shape
                cornerPoints = cv2.approxPolyDP(cnt, 0.01 * peri, True)
                if area &gt; maxArea and len(cornerPoints) == 4:
                    cornerPointsOfMaxArea = cornerPoints
                    maxArea = area

        return cornerPointsOfMaxArea

    def getWarp(self, image: Image, pageCoordinates: np.ndarray):
        &#34;&#34;&#34;
        Warps the image based on the given coordinates.

        Parameters
        ----------
        :param image : Image
            The input image.
        :param pageCoordinates : np.ndarray
            The coordinates for warping the image.

        Returns
        -------
        :return Image
            The warped image.
        &#34;&#34;&#34;

        if not pageCoordinates.any():  # when object&#39;s perimeter is partly covered
            prev_coord_points = self.oldCoordinates[:]

            if len(prev_coord_points) &lt; 1:
                return image

            image = self.setPerspective(image, prev_coord_points)
        else:
            new_coord_points = np.reshape(pageCoordinates, (4, 2))
            self.oldCoordinates = new_coord_points[:]

            image = self.setPerspective(image, new_coord_points)

        return image

    def setPerspective(self, image: Image, cords: np.ndarray):
        &#34;&#34;&#34;
        Sets the perspective transform for the image.

        Parameters
        ----------
        :param image : Image
            The input image.
        :param cords : np.ndarray
            The coordinates for perspective transform.

        Returns
        -------
        :return Image
            The perspective transformed image.
        &#34;&#34;&#34;

        pts1 = np.float32([cords[1], cords[0], cords[2], cords[3]])
        pts2 = np.float32([[0, 0], [self.frameWidth, 0], [0, self.frameHeight], [self.frameWidth, self.frameHeight]])
        matrix = cv2.getPerspectiveTransform(pts1, pts2)
        return cv2.warpPerspective(image, matrix, (self.frameWidth, self.frameHeight))

    def postProcess(self, image: Image):
        &#34;&#34;&#34;
        Post-processes the image by rotating and cropping edges.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The post-processed image.
        &#34;&#34;&#34;

        rotatedImage = cv2.rotate(image, cv2.ROTATE_180)
        return rotatedImage[self.edgeSize:rotatedImage.shape[0] - self.edgeSize,
                            self.edgeSize:rotatedImage.shape[1] - self.edgeSize]

    def processImage(self, image: Image):
        &#34;&#34;&#34;
        Processes the image to find and warp the largest contour.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The processed image.
        &#34;&#34;&#34;

        imgPreprocessed = self.preProcessing(image)
        contours = self.getCornerPoints(imgPreprocessed)
        imgWarp = self.getWarp(image, contours)
        return self.postProcess(imgWarp)

    def getPenFromImage(self, image: Image):
        &#34;&#34;&#34;
        Detects the pen in the image and draws its movement on the canvas.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The canvas with pen movements drawn.
        &#34;&#34;&#34;

        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        mask = cv2.inRange(hsv, self.colorValues[0], self.colorValues[1])
        mask = cv2.erode(mask, self.kernel, iterations=1)
        mask = cv2.dilate(mask, self.kernel, iterations=2)

        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours and cv2.contourArea(max(contours, key=cv2.contourArea)) &gt; self.noiseArea:
            c = max(contours, key=cv2.contourArea)
            x2, y2, w, h = cv2.boundingRect(c)
            x2 = 1920 - x2
            y2 = 1080 - y2

            if self.penCords[0] != 0 or self.penCords[1] != 0:
                self.canvas = cv2.line(self.canvas, self.penCords, (x2, y2), self.penColor, 6)

            self.penCords = (x2, y2)

        return self.canvas

    def startScanner(self):
        &#34;&#34;&#34;
        Starts the video capture for scanning.
        &#34;&#34;&#34;

        self.video = cv2.VideoCapture(0)
        self.video.set(3, self.frameWidth)
        self.video.set(4, self.frameHeight)
        self.video.set(100, 150)
        self.canvas = np.zeros_like(self.video.read()[1])

    def stopScanner(self):
        &#34;&#34;&#34;
        Stops the video capture.
        &#34;&#34;&#34;

        cv2.destroyAllWindows()
        self.video = None

    def getFinalImage(self):
        &#34;&#34;&#34;
        Gets the final processed image with pen movements.

        Returns
        -------
        :return np.ndarray
            The final image with pen movements.
        &#34;&#34;&#34;

        image = self.video.read()[1]
        processedImage = self.processImage(image)
        return self.getPenFromImage(processedImage)

    def getColorsImage(self, lower: np.ndarray, higher: np.ndarray):
        &#34;&#34;&#34;
        Gets the image filtered by the specified HSV color range.

        Parameters
        ----------
        :param lower : np.ndarray
            Lower HSV color range.
        :param higher : np.ndarray
            Higher HSV color range.
        &#34;&#34;&#34;

        image = self.video.read()[1]

        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        res = cv2.bitwise_and(image, image, mask=cv2.inRange(hsv, lower, higher))

        return res

    @staticmethod
    def mergeImages(bottomLayer: Image, topLayer: Image):
        &#34;&#34;&#34;
        Merges two images with alpha blending.

        Parameters
        ----------
        :param bottomLayer : Image
            The bottom image layer.
        :param topLayer : Image
            The top image layer.

        Returns
        -------
        :return np.ndarray
            The merged image with alpha blending.
        &#34;&#34;&#34;

        bottomLayer = cv2.cvtColor(np.array(bottomLayer), cv2.COLOR_RGB2RGBA)
        topLayer = cv2.cvtColor(np.array(topLayer), cv2.COLOR_RGB2RGBA)

        topLayer = cv2.resize(topLayer, (bottomLayer.shape[1], bottomLayer.shape[0]))
        return cv2.addWeighted(bottomLayer, 1, topLayer, 1, 0.0)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="modules.scannerService.ScannerService"><code class="flex name class">
<span>class <span class="ident">ScannerService</span></span>
<span>(</span><span>colorValues: [<built-in function array>, <built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>A class used to perform various scanning operations.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>video</code></strong> :&ensp;<code>cv2.VideoCapture</code> or <code>None</code></dt>
<dd>Video capture object for webcam (default None)</dd>
<dt><strong><code>frameWidth</code></strong> :&ensp;<code>int</code></dt>
<dd>Width of the video frame (default 1920)</dd>
<dt><strong><code>frameHeight</code></strong> :&ensp;<code>int</code></dt>
<dd>Height of the video frame (default 1080)</dd>
<dt><strong><code>edgeSize</code></strong> :&ensp;<code>int</code></dt>
<dd>Size of the edge to crop (default 0)</dd>
<dt><strong><code>oldCoordinates</code></strong> :&ensp;<code>list</code></dt>
<dd>List to store old coordinates (default empty list)</dd>
<dt><strong><code>colorValues</code></strong> :&ensp;<code>list</code> of <code>array</code></dt>
<dd>HSV color range for pen detection</dd>
<dt><strong><code>kernel</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Kernel for morphological operations (default np.ones((5, 5)))</dd>
<dt><strong><code>noiseArea</code></strong> :&ensp;<code>int</code></dt>
<dd>Minimum area to be considered as valid pen detection (default 200)</dd>
<dt><strong><code>canvas</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Canvas to draw the detected pen movements (default None)</dd>
<dt><strong><code>penCords</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Coordinates of the pen (default (0, 0))</dd>
<dt><strong><code>penColor</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Color of the pen (default [255, 0, 0])</dd>
</dl>
<h2 id="methods">Methods</h2>
<p>preProcessing(image: Image):
Preprocesses the image to find edges.
getCornerPoints(image: Image):
Finds the corner points of the largest contour.
getWarp(image: Image, pageCoordinates: np.ndarray):
Warps the image based on the given coordinates.
setPerspective(image: Image, cords: np.ndarray):
Sets the perspective transform for the image.
postProcess(image: Image):
Post-processes the image by rotating and cropping edges.
processImage(image: Image):
Processes the image to find and warp the largest contour.
getPenFromImage(image: Image):
Detects the pen in the image and draws its movement on the canvas.
startScanner():
Starts the video capture for scanning.
stopScanner():
Stops the video capture.
getFinalImage():
Gets the final processed image with pen movements.
getColorsImage(lower: np.ndarray, higher: np.ndarray):
Gets the image filtered by the specified HSV color range.
mergeImages(bottomLayer: Image, topLayer: Image):
Merges two images with alpha blending.</p>
<p>:param colorValues:
Color values of detected pen(default read from file)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ScannerService:
    &#34;&#34;&#34;
    A class used to perform various scanning operations.

    Attributes
    ----------
    video : cv2.VideoCapture or None
        Video capture object for webcam (default None)
    frameWidth : int
        Width of the video frame (default 1920)
    frameHeight : int
        Height of the video frame (default 1080)
    edgeSize : int
        Size of the edge to crop (default 0)
    oldCoordinates : list
        List to store old coordinates (default empty list)
    colorValues : list of array
        HSV color range for pen detection
    kernel : np.ndarray
        Kernel for morphological operations (default np.ones((5, 5)))
    noiseArea : int
        Minimum area to be considered as valid pen detection (default 200)
    canvas : np.ndarray
        Canvas to draw the detected pen movements (default None)
    penCords : tuple
        Coordinates of the pen (default (0, 0))
    penColor : tuple
        Color of the pen (default [255, 0, 0])

    Methods
    -------
    preProcessing(image: Image):
        Preprocesses the image to find edges.
    getCornerPoints(image: Image):
        Finds the corner points of the largest contour.
    getWarp(image: Image, pageCoordinates: np.ndarray):
        Warps the image based on the given coordinates.
    setPerspective(image: Image, cords: np.ndarray):
        Sets the perspective transform for the image.
    postProcess(image: Image):
        Post-processes the image by rotating and cropping edges.
    processImage(image: Image):
        Processes the image to find and warp the largest contour.
    getPenFromImage(image: Image):
        Detects the pen in the image and draws its movement on the canvas.
    startScanner():
        Starts the video capture for scanning.
    stopScanner():
        Stops the video capture.
    getFinalImage():
        Gets the final processed image with pen movements.
    getColorsImage(lower: np.ndarray, higher: np.ndarray):
        Gets the image filtered by the specified HSV color range.
    mergeImages(bottomLayer: Image, topLayer: Image):
        Merges two images with alpha blending.
    &#34;&#34;&#34;

    def __init__(self, colorValues: [np.array, np.array]):
        &#34;&#34;&#34;
        :param colorValues:
            Color values of detected pen(default read from file)
        &#34;&#34;&#34;

        self.video: cv2.VideoCapture | None = None
        self.frameWidth: int = 1920
        self.frameHeight: int = 1080
        self.edgeSize: int = 0
        self.oldCoordinates: list = []
        self.colorValues: [np.array, np.array] = colorValues
        self.kernel: np.ndarray = np.ones((5, 5))
        self.noiseArea: int = 200
        self.canvas: np.array = None
        self.penCords: tuple[int, int] = (0, 0)
        self.penColor: tuple[int, int, int] = (255, 0, 0)

    def preProcessing(self, image: Image):
        &#34;&#34;&#34;
        Preprocesses the image to find edges.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The preprocessed image with edges detected.
        &#34;&#34;&#34;

        imgGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Gray image
        imgBlur = cv2.GaussianBlur(imgGray, (1, 1), 1)  # Blur Image - easing edges
        imgCanny = cv2.Canny(imgBlur, 100, 300)  # Canny Image - canny algo to find edges

        # extending the found edges and then eroding it to smoothen the image
        imgDilate = cv2.dilate(imgCanny, self.kernel, iterations=2)
        imgErode = cv2.erode(imgDilate, self.kernel, iterations=1)
        return imgErode

    @staticmethod
    def getCornerPoints(image: Image):
        &#34;&#34;&#34;
        Finds the corner points of the largest contour.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The corner points of the largest contour.
        &#34;&#34;&#34;

        cornerPointsOfMaxArea = np.array([])
        maxArea = 0
        contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area &gt; 100000:  # area in px x px
                peri = cv2.arcLength(cnt, True)  # perimeter of the closed shape
                cornerPoints = cv2.approxPolyDP(cnt, 0.01 * peri, True)
                if area &gt; maxArea and len(cornerPoints) == 4:
                    cornerPointsOfMaxArea = cornerPoints
                    maxArea = area

        return cornerPointsOfMaxArea

    def getWarp(self, image: Image, pageCoordinates: np.ndarray):
        &#34;&#34;&#34;
        Warps the image based on the given coordinates.

        Parameters
        ----------
        :param image : Image
            The input image.
        :param pageCoordinates : np.ndarray
            The coordinates for warping the image.

        Returns
        -------
        :return Image
            The warped image.
        &#34;&#34;&#34;

        if not pageCoordinates.any():  # when object&#39;s perimeter is partly covered
            prev_coord_points = self.oldCoordinates[:]

            if len(prev_coord_points) &lt; 1:
                return image

            image = self.setPerspective(image, prev_coord_points)
        else:
            new_coord_points = np.reshape(pageCoordinates, (4, 2))
            self.oldCoordinates = new_coord_points[:]

            image = self.setPerspective(image, new_coord_points)

        return image

    def setPerspective(self, image: Image, cords: np.ndarray):
        &#34;&#34;&#34;
        Sets the perspective transform for the image.

        Parameters
        ----------
        :param image : Image
            The input image.
        :param cords : np.ndarray
            The coordinates for perspective transform.

        Returns
        -------
        :return Image
            The perspective transformed image.
        &#34;&#34;&#34;

        pts1 = np.float32([cords[1], cords[0], cords[2], cords[3]])
        pts2 = np.float32([[0, 0], [self.frameWidth, 0], [0, self.frameHeight], [self.frameWidth, self.frameHeight]])
        matrix = cv2.getPerspectiveTransform(pts1, pts2)
        return cv2.warpPerspective(image, matrix, (self.frameWidth, self.frameHeight))

    def postProcess(self, image: Image):
        &#34;&#34;&#34;
        Post-processes the image by rotating and cropping edges.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The post-processed image.
        &#34;&#34;&#34;

        rotatedImage = cv2.rotate(image, cv2.ROTATE_180)
        return rotatedImage[self.edgeSize:rotatedImage.shape[0] - self.edgeSize,
                            self.edgeSize:rotatedImage.shape[1] - self.edgeSize]

    def processImage(self, image: Image):
        &#34;&#34;&#34;
        Processes the image to find and warp the largest contour.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The processed image.
        &#34;&#34;&#34;

        imgPreprocessed = self.preProcessing(image)
        contours = self.getCornerPoints(imgPreprocessed)
        imgWarp = self.getWarp(image, contours)
        return self.postProcess(imgWarp)

    def getPenFromImage(self, image: Image):
        &#34;&#34;&#34;
        Detects the pen in the image and draws its movement on the canvas.

        Parameters
        ----------
        :param image : Image
            The input image.

        Returns
        -------
        :return np.ndarray
            The canvas with pen movements drawn.
        &#34;&#34;&#34;

        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        mask = cv2.inRange(hsv, self.colorValues[0], self.colorValues[1])
        mask = cv2.erode(mask, self.kernel, iterations=1)
        mask = cv2.dilate(mask, self.kernel, iterations=2)

        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours and cv2.contourArea(max(contours, key=cv2.contourArea)) &gt; self.noiseArea:
            c = max(contours, key=cv2.contourArea)
            x2, y2, w, h = cv2.boundingRect(c)
            x2 = 1920 - x2
            y2 = 1080 - y2

            if self.penCords[0] != 0 or self.penCords[1] != 0:
                self.canvas = cv2.line(self.canvas, self.penCords, (x2, y2), self.penColor, 6)

            self.penCords = (x2, y2)

        return self.canvas

    def startScanner(self):
        &#34;&#34;&#34;
        Starts the video capture for scanning.
        &#34;&#34;&#34;

        self.video = cv2.VideoCapture(0)
        self.video.set(3, self.frameWidth)
        self.video.set(4, self.frameHeight)
        self.video.set(100, 150)
        self.canvas = np.zeros_like(self.video.read()[1])

    def stopScanner(self):
        &#34;&#34;&#34;
        Stops the video capture.
        &#34;&#34;&#34;

        cv2.destroyAllWindows()
        self.video = None

    def getFinalImage(self):
        &#34;&#34;&#34;
        Gets the final processed image with pen movements.

        Returns
        -------
        :return np.ndarray
            The final image with pen movements.
        &#34;&#34;&#34;

        image = self.video.read()[1]
        processedImage = self.processImage(image)
        return self.getPenFromImage(processedImage)

    def getColorsImage(self, lower: np.ndarray, higher: np.ndarray):
        &#34;&#34;&#34;
        Gets the image filtered by the specified HSV color range.

        Parameters
        ----------
        :param lower : np.ndarray
            Lower HSV color range.
        :param higher : np.ndarray
            Higher HSV color range.
        &#34;&#34;&#34;

        image = self.video.read()[1]

        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        res = cv2.bitwise_and(image, image, mask=cv2.inRange(hsv, lower, higher))

        return res

    @staticmethod
    def mergeImages(bottomLayer: Image, topLayer: Image):
        &#34;&#34;&#34;
        Merges two images with alpha blending.

        Parameters
        ----------
        :param bottomLayer : Image
            The bottom image layer.
        :param topLayer : Image
            The top image layer.

        Returns
        -------
        :return np.ndarray
            The merged image with alpha blending.
        &#34;&#34;&#34;

        bottomLayer = cv2.cvtColor(np.array(bottomLayer), cv2.COLOR_RGB2RGBA)
        topLayer = cv2.cvtColor(np.array(topLayer), cv2.COLOR_RGB2RGBA)

        topLayer = cv2.resize(topLayer, (bottomLayer.shape[1], bottomLayer.shape[0]))
        return cv2.addWeighted(bottomLayer, 1, topLayer, 1, 0.0)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="modules.scannerService.ScannerService.getCornerPoints"><code class="name flex">
<span>def <span class="ident">getCornerPoints</span></span>(<span>image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the corner points of the largest contour.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The corner points of the largest contour.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def getCornerPoints(image: Image):
    &#34;&#34;&#34;
    Finds the corner points of the largest contour.

    Parameters
    ----------
    :param image : Image
        The input image.

    Returns
    -------
    :return np.ndarray
        The corner points of the largest contour.
    &#34;&#34;&#34;

    cornerPointsOfMaxArea = np.array([])
    maxArea = 0
    contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area &gt; 100000:  # area in px x px
            peri = cv2.arcLength(cnt, True)  # perimeter of the closed shape
            cornerPoints = cv2.approxPolyDP(cnt, 0.01 * peri, True)
            if area &gt; maxArea and len(cornerPoints) == 4:
                cornerPointsOfMaxArea = cornerPoints
                maxArea = area

    return cornerPointsOfMaxArea</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.mergeImages"><code class="name flex">
<span>def <span class="ident">mergeImages</span></span>(<span>bottomLayer: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>, topLayer: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Merges two images with alpha blending.</p>
<h2 id="parameters">Parameters</h2>
<p>:param bottomLayer : Image
The bottom image layer.
:param topLayer : Image
The top image layer.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The merged image with alpha blending.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def mergeImages(bottomLayer: Image, topLayer: Image):
    &#34;&#34;&#34;
    Merges two images with alpha blending.

    Parameters
    ----------
    :param bottomLayer : Image
        The bottom image layer.
    :param topLayer : Image
        The top image layer.

    Returns
    -------
    :return np.ndarray
        The merged image with alpha blending.
    &#34;&#34;&#34;

    bottomLayer = cv2.cvtColor(np.array(bottomLayer), cv2.COLOR_RGB2RGBA)
    topLayer = cv2.cvtColor(np.array(topLayer), cv2.COLOR_RGB2RGBA)

    topLayer = cv2.resize(topLayer, (bottomLayer.shape[1], bottomLayer.shape[0]))
    return cv2.addWeighted(bottomLayer, 1, topLayer, 1, 0.0)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="modules.scannerService.ScannerService.getColorsImage"><code class="name flex">
<span>def <span class="ident">getColorsImage</span></span>(<span>self, lower: numpy.ndarray, higher: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the image filtered by the specified HSV color range.</p>
<h2 id="parameters">Parameters</h2>
<p>:param lower : np.ndarray
Lower HSV color range.
:param higher : np.ndarray
Higher HSV color range.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getColorsImage(self, lower: np.ndarray, higher: np.ndarray):
    &#34;&#34;&#34;
    Gets the image filtered by the specified HSV color range.

    Parameters
    ----------
    :param lower : np.ndarray
        Lower HSV color range.
    :param higher : np.ndarray
        Higher HSV color range.
    &#34;&#34;&#34;

    image = self.video.read()[1]

    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    res = cv2.bitwise_and(image, image, mask=cv2.inRange(hsv, lower, higher))

    return res</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.getFinalImage"><code class="name flex">
<span>def <span class="ident">getFinalImage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the final processed image with pen movements.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The final image with pen movements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getFinalImage(self):
    &#34;&#34;&#34;
    Gets the final processed image with pen movements.

    Returns
    -------
    :return np.ndarray
        The final image with pen movements.
    &#34;&#34;&#34;

    image = self.video.read()[1]
    processedImage = self.processImage(image)
    return self.getPenFromImage(processedImage)</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.getPenFromImage"><code class="name flex">
<span>def <span class="ident">getPenFromImage</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Detects the pen in the image and draws its movement on the canvas.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The canvas with pen movements drawn.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getPenFromImage(self, image: Image):
    &#34;&#34;&#34;
    Detects the pen in the image and draws its movement on the canvas.

    Parameters
    ----------
    :param image : Image
        The input image.

    Returns
    -------
    :return np.ndarray
        The canvas with pen movements drawn.
    &#34;&#34;&#34;

    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    mask = cv2.inRange(hsv, self.colorValues[0], self.colorValues[1])
    mask = cv2.erode(mask, self.kernel, iterations=1)
    mask = cv2.dilate(mask, self.kernel, iterations=2)

    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours and cv2.contourArea(max(contours, key=cv2.contourArea)) &gt; self.noiseArea:
        c = max(contours, key=cv2.contourArea)
        x2, y2, w, h = cv2.boundingRect(c)
        x2 = 1920 - x2
        y2 = 1080 - y2

        if self.penCords[0] != 0 or self.penCords[1] != 0:
            self.canvas = cv2.line(self.canvas, self.penCords, (x2, y2), self.penColor, 6)

        self.penCords = (x2, y2)

    return self.canvas</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.getWarp"><code class="name flex">
<span>def <span class="ident">getWarp</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>, pageCoordinates: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Warps the image based on the given coordinates.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.
:param pageCoordinates : np.ndarray
The coordinates for warping the image.</p>
<h2 id="returns">Returns</h2>
<p>:return Image
The warped image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getWarp(self, image: Image, pageCoordinates: np.ndarray):
    &#34;&#34;&#34;
    Warps the image based on the given coordinates.

    Parameters
    ----------
    :param image : Image
        The input image.
    :param pageCoordinates : np.ndarray
        The coordinates for warping the image.

    Returns
    -------
    :return Image
        The warped image.
    &#34;&#34;&#34;

    if not pageCoordinates.any():  # when object&#39;s perimeter is partly covered
        prev_coord_points = self.oldCoordinates[:]

        if len(prev_coord_points) &lt; 1:
            return image

        image = self.setPerspective(image, prev_coord_points)
    else:
        new_coord_points = np.reshape(pageCoordinates, (4, 2))
        self.oldCoordinates = new_coord_points[:]

        image = self.setPerspective(image, new_coord_points)

    return image</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.postProcess"><code class="name flex">
<span>def <span class="ident">postProcess</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Post-processes the image by rotating and cropping edges.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The post-processed image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def postProcess(self, image: Image):
    &#34;&#34;&#34;
    Post-processes the image by rotating and cropping edges.

    Parameters
    ----------
    :param image : Image
        The input image.

    Returns
    -------
    :return np.ndarray
        The post-processed image.
    &#34;&#34;&#34;

    rotatedImage = cv2.rotate(image, cv2.ROTATE_180)
    return rotatedImage[self.edgeSize:rotatedImage.shape[0] - self.edgeSize,
                        self.edgeSize:rotatedImage.shape[1] - self.edgeSize]</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.preProcessing"><code class="name flex">
<span>def <span class="ident">preProcessing</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Preprocesses the image to find edges.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The preprocessed image with edges detected.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preProcessing(self, image: Image):
    &#34;&#34;&#34;
    Preprocesses the image to find edges.

    Parameters
    ----------
    :param image : Image
        The input image.

    Returns
    -------
    :return np.ndarray
        The preprocessed image with edges detected.
    &#34;&#34;&#34;

    imgGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Gray image
    imgBlur = cv2.GaussianBlur(imgGray, (1, 1), 1)  # Blur Image - easing edges
    imgCanny = cv2.Canny(imgBlur, 100, 300)  # Canny Image - canny algo to find edges

    # extending the found edges and then eroding it to smoothen the image
    imgDilate = cv2.dilate(imgCanny, self.kernel, iterations=2)
    imgErode = cv2.erode(imgDilate, self.kernel, iterations=1)
    return imgErode</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.processImage"><code class="name flex">
<span>def <span class="ident">processImage</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Processes the image to find and warp the largest contour.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.</p>
<h2 id="returns">Returns</h2>
<p>:return np.ndarray
The processed image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processImage(self, image: Image):
    &#34;&#34;&#34;
    Processes the image to find and warp the largest contour.

    Parameters
    ----------
    :param image : Image
        The input image.

    Returns
    -------
    :return np.ndarray
        The processed image.
    &#34;&#34;&#34;

    imgPreprocessed = self.preProcessing(image)
    contours = self.getCornerPoints(imgPreprocessed)
    imgWarp = self.getWarp(image, contours)
    return self.postProcess(imgWarp)</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.setPerspective"><code class="name flex">
<span>def <span class="ident">setPerspective</span></span>(<span>self, image: <module 'PIL.Image' from '/Users/jankozub/Documents/LiveScanner/.venv/lib/python3.12/site-packages/PIL/Image.py'>, cords: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the perspective transform for the image.</p>
<h2 id="parameters">Parameters</h2>
<p>:param image : Image
The input image.
:param cords : np.ndarray
The coordinates for perspective transform.</p>
<h2 id="returns">Returns</h2>
<p>:return Image
The perspective transformed image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setPerspective(self, image: Image, cords: np.ndarray):
    &#34;&#34;&#34;
    Sets the perspective transform for the image.

    Parameters
    ----------
    :param image : Image
        The input image.
    :param cords : np.ndarray
        The coordinates for perspective transform.

    Returns
    -------
    :return Image
        The perspective transformed image.
    &#34;&#34;&#34;

    pts1 = np.float32([cords[1], cords[0], cords[2], cords[3]])
    pts2 = np.float32([[0, 0], [self.frameWidth, 0], [0, self.frameHeight], [self.frameWidth, self.frameHeight]])
    matrix = cv2.getPerspectiveTransform(pts1, pts2)
    return cv2.warpPerspective(image, matrix, (self.frameWidth, self.frameHeight))</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.startScanner"><code class="name flex">
<span>def <span class="ident">startScanner</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Starts the video capture for scanning.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def startScanner(self):
    &#34;&#34;&#34;
    Starts the video capture for scanning.
    &#34;&#34;&#34;

    self.video = cv2.VideoCapture(0)
    self.video.set(3, self.frameWidth)
    self.video.set(4, self.frameHeight)
    self.video.set(100, 150)
    self.canvas = np.zeros_like(self.video.read()[1])</code></pre>
</details>
</dd>
<dt id="modules.scannerService.ScannerService.stopScanner"><code class="name flex">
<span>def <span class="ident">stopScanner</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Stops the video capture.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stopScanner(self):
    &#34;&#34;&#34;
    Stops the video capture.
    &#34;&#34;&#34;

    cv2.destroyAllWindows()
    self.video = None</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="modules" href="index.html">modules</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="modules.scannerService.ScannerService" href="#modules.scannerService.ScannerService">ScannerService</a></code></h4>
<ul class="two-column">
<li><code><a title="modules.scannerService.ScannerService.getColorsImage" href="#modules.scannerService.ScannerService.getColorsImage">getColorsImage</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.getCornerPoints" href="#modules.scannerService.ScannerService.getCornerPoints">getCornerPoints</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.getFinalImage" href="#modules.scannerService.ScannerService.getFinalImage">getFinalImage</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.getPenFromImage" href="#modules.scannerService.ScannerService.getPenFromImage">getPenFromImage</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.getWarp" href="#modules.scannerService.ScannerService.getWarp">getWarp</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.mergeImages" href="#modules.scannerService.ScannerService.mergeImages">mergeImages</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.postProcess" href="#modules.scannerService.ScannerService.postProcess">postProcess</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.preProcessing" href="#modules.scannerService.ScannerService.preProcessing">preProcessing</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.processImage" href="#modules.scannerService.ScannerService.processImage">processImage</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.setPerspective" href="#modules.scannerService.ScannerService.setPerspective">setPerspective</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.startScanner" href="#modules.scannerService.ScannerService.startScanner">startScanner</a></code></li>
<li><code><a title="modules.scannerService.ScannerService.stopScanner" href="#modules.scannerService.ScannerService.stopScanner">stopScanner</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>